load_ckpt_from_pretrained:
load_ckpt:

#FOR TEST EVAL
save_xyz: true
calculate_energy: true
num_test_graphs: 10000
inference_batch_size: 8
use_ligand_dataset_sizes: true
# test_save_dir: /hpfs/userws/let55/experiments/e3moldiffusion/crossdocked/test_tuan

bond_model_guidance: false
bond_prediction: false

joint_property_prediction: true
regression_property: "sa_score"

seed: 42
batch_size: 8
ema_decay: 0.999
grad_clip_val: 10.0
accum_batch: 1
gamma: 0.99

use_adaptive_loader: false
remove_hs: true

gpus: 8
num_epochs: 301
test_interval: 20

#EQGAT
sdim: 256
vdim: 256
edim: 128
num_layers: 12
use_cross_product: false
edge_mp: false
fully_connected: true
local_global_model: false
vector_aggr: mean
num_bond_classes: 5
cutoff_local: 5.0
cutoff_global: 5.0
hybrid_knn:
knn:
knn_with_cutoff:
ligand_pocket_interaction: true
use_pos_norm: false
use_out_norm: true
use_rbfs: true
model_edge_rbf_interaction: true
model_global_edge: true
mask_pocket_edges: false
num_bond_classes: 5
prior_n_atoms: targetdiff
ligand_pocket_distance_loss: false
ligand_pocket_hidden_distance: false
context_mapping: true
use_lipinski_properties: true
num_context_features: 5
use_centroid_context_embed: true

# LATENT
sdim_latent: 128
vdim_latent: 128
edim_latent: 16
num_layers_latent: 8
latent_dim: 128
use_cross_product: false
local_edge_attrs: false
fully_connected: true
local_global_model: false
dropout_prob: 0.2
use_pos_norm_latent: false
use_out_norm_latent: true
use_latent_encoder: true
use_scaffold_latent_embed: false

#DATA
dataset: crossdocked
dataset_root: /scratch1/e3moldiffusion/data/crossdocked/crossdocked_noH_cutoff5_TargetDiff_atmass
dataset_cutoff: 5.0

# DIFFUSION
additional_feats: false
continuous: false
noise_scheduler: adaptive
eps_min: 1.e-3
beta_min: 1.e-4
beta_max: 2.e-2
timesteps: 500
max_time: 09:00:00:00
loss_weighting: snr_t
latentmodel: mmd
prior_beta: 1.0

#LOGGING
save_dir: /scratch1/e3moldiffusion/logs/crossdocked/latent_tuan/x0_snr_cutoff5_bonds5_out-norm_rbf-5A_edge-stuff_joint-sa_expScheduler_contextLipinski_clusterEmbed/
id: 0

#LEARNING
lr_scheduler: exponential # reduce_on_plateau
lr: 2.e-4
lr_min: 5.e-5 #used for cyclic scheduler
lr_step_size: 5.e-5 #used for cyclic scheduler
lr_factor: 0.75
lr_patience: 20
max_num_neighbors: 128
weight_decay: 1.e-12

num_workers: 6
precision: 32